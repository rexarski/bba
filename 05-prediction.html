<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Cluster Prediction - Rui Qiu</title>
    <link rel="stylesheet" href="css/style.css">
</head>

<body class="sidebar">
    <nav>
        ◀️ <a href="index.html" class="return-button">Back</a>
        <ul>
            <li><a href="#background">Background</a></li>
            <li><a href="#method">Method</a></li>
            <li><a href="#results">Results</a></li>
            <li><a href="#discussion">Discussion</a></li>
        </ul>

        <svg xmlns=" http://www.w3.org/2000/svg">
            <path />
        </svg>

    </nav>
    <article id="top">
        <div class="subheading">Part 5 Extra: Cluster Prediction</div>
        <h1>Where are these five players fitting in?</h1>

        <p>Rui Qiu</p>
        <p>Updated on 2021-10-11.</p>
        <br>

        <p><span>Please refer to the </span><a href='05-clustering.html'><span>last chapter</span></a><span> for more
                details. The script used, however, is still the one for clustering.</span></p>
        <blockquote>
            <ul>
                <li><span>GitHub repo: </span><a href='https://github.com/rexarski/box2box'><span>box2box</span></a>
                </li>
                <li><span>R script for clustering and predictions: </span><a
                        href='https://github.com/rexarski/box2box/blob/main/nba-player-clustering/clustering.R'><span>clustering.R</span></a>
                </li>
            </ul>
        </blockquote>

        <section id="background">
            <h2><span>Background</span></h2>
            <p><span>Adding some new record to an existing clustering is not always a good idea since clustering itself
                    is an
                    unsupervised learning. It heavily relies on the “training” data. So here’s the best case: if the
                    newly added
                    data are not very extreme, nor are they very influential in quantity (say greater than 10% of the
                    previous
                    data), then they are good. Otherwise, the centroids might better be recalculated.</span></p>
        </section>

        <section id="method">
            <h2><span>Method</span></h2>
            <p><span>Before doing anything practical, let’s take a look at the current clustering for optimal value
                    $\ k=3$.</span>

            <figure>
                <img src="img/05-02-predictive-cluster-k3.png" alt="predictive-cluster-k3" class="article-img">
                <figcaption>Clusters for $k=3$. <br>Open in new tab to see in full size.</figcaption>
            </figure>

            <p><span>The KNN (</span><em><span>k-nearest neighbors</span></em><span>) algorithm is the perfect
                    solution to the
                    introduction of new individuals. Specifically, the existing 50 players are grouped into the
                    following three
                    groups:</span></p>
            <figure>
                <table>
                    <thead>
                        <tr>
                            <th style='text-align:right;'><span>Group 1</span></th>
                            <th style='text-align:right;'><span>Group 2</span></th>
                            <th style='text-align:right;'><span>Group 3</span></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style='text-align:right;'><span>21</span></td>
                            <td style='text-align:right;'><span>22</span></td>
                            <td style='text-align:right;'><span>7</span></td>
                        </tr>
                    </tbody>
                </table>
            </figure>
            <p><span>The KNN calculates the distance between labeled training data and the new instance through some
                    similarity measures, e.g., the Euclidean distance. Then the sample will be distributed to the
                    cluster that is
                    the closest to.</span></p>

        </section>

        <section id="results">
            <h2><span>Results</span></h2>
            <p><span>The new addition of data is five players ranked by playing minutes from the 51-55th place. And the
                    KNN
                    predictive results are:</span></p>

            <pre>
                [1] 1 1 1 1 3
                Levels: 1 2 3
            </pre>

            <p><span>This means four of them are predicted to be in Group 1, and the last one in Group 3.</span></p>
            <p><span>Visually, a scatter plot would do the explanation. The newly added player names are enlarged in
                    text
                    labels.</span></p>

            <figure>
                <img src="img/05-02-predictive-new-k3.png" alt="predictive-new-k3" class="article-img">
                <figcaption>Predictive results based on KNN.<br>Open in new tab to see in full size.
                </figcaption>
            </figure>
        </section>

        <section id="discussion">
            <h2><span>Discussion</span></h2>
            <p><span>As mentioned above, using clustering as a predictive model is not always the first choice for
                    classification.
                    The KNN should be based on some real-labeled data instead of using clustered groups as the
                    &quot;labels.&quot;</span></p>
            <p><span>Furthermore, the prediction made by KNN based on $\ k=3$ clustering is problematic:</span>
            <ul>
                <li><span>Ben Simmons is actually located within cluster 2 but marked as cluster 3.</span></li>
                <li><span>Ja Morant is marked as cluster 1 but resides within cluster 3.</span></li>
                <li><span>Tobias Harris, along with Julius Randle from the previous data set, though marked as cluster
                        1, but indeed
                        stay closer to cluster 2.</span></li>
            </ul>
            <p><span>These are all drawbacks of clustering NBA players by their statistics, which are eventually
                    discussed in the
                </span><a href='05-clustering.html/#17summary'><span>summary part of Part 1</span></a><span>.</span></p>
        </section>

        <hr>

        <footer class="footer">
            <p>Copyright &copy; 2021 <a href="https://qrui.xyz">Ruì Qiū</a></p>
        </footer>
    </article>

    <script src="js/script.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };</script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</body>

</html>