<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Data Gathering - Rui Qiu</title>
    <link rel="stylesheet" href="css/style.css">
</head>

<body class="sidebar">
    <nav>
        ◀️ <a href="index.html" class="return-button">Back</a>
        <ul>
            <li>
                <a href="#sources">Data sources</a>
            </li>
            <li>
                <a href="#methods">Gathering methods</a>
                <ul>
                    <li><a href="#pbp">Play-by-play data</a></li>
                    <li><a href="#twitter">Twitter</a>
                        <ul>
                            <li><a href="#tweet">Tweets</a></li>
                            <li><a href="#account">Accounts</a></li>
                        </ul>
                    </li>
                    <li><a href="#reddit">Reddit</a></li>
                    <li><a href="#fivethirtyeight">FiveThirtyEight</a>
                        <ul>
                            <li><a href="#raptor">RAPTOR</a></li>
                            <li><a href="#draymond">DRAYMOND</a></li>
                            <li><a href="#more">More</a></li>
                        </ul>
                    </li>
                    <li><a href="#pudding">The Pudding</a>
                        <ul>
                            <li><a href="#last-two-minute-report">last-two-min</a></li>
                            <li><a href="#hype">hype</a></li>
                            <li><a href="#names">player-names</a></li>
                            <li><a href="#three-seconds">three-seconds</a></li>
                        </ul>
                    </li>
                    <li><a href="#google-trends">Google Trends</a></li>
                    <li><a href="#support">Supporting data</a></li>
                </ul>
            </li>
        </ul>

        <svg xmlns=" http://www.w3.org/2000/svg">
            <path />
        </svg>

    </nav>
    <article id="top">
        <div class="subheading">Part 2: Data Gathering</div>
        <h1>The sources and the methods</h1>

        <p>Rui Qiu</p>
        <p>Updated on 2021-09-16.</p>
        <br>

        <blockquote>Check out the GitHub repository for the <a
                href="https://github.com/rexarski/rqiu.georgetown.domains/"><b>source code</b></a> and the <a
                href="https://github.com/rexarski/box2box/"><b>data</b></a>.</blockquote>

        <figure>
            <img src="https://imgs.xkcd.com/comics/flawed_data.png" alt="Flawed Data" class="article-img">
            <figcaption>xkcd <a href="https://xkcd.com/2494/">2494</a>
            </figcaption>
        </figure>

        <p>This part includes two sections, one listing all (potential) data sources and one detailing how I
            retrieved
            the data.</p>

        <section id="sources">
            <h2>Data sources</h2>
            <ul>
                <li>Play-by-play data from <a href="https://tracking.pbpstats.com/">PBP Stats Tracking</a>, which merges
                    hand-tracked data and tracking stats from <a href="https://www.nba.com/stats/">NBA Stats</a>.</li>
                <li>Tweets (text data) from <a href="https://twitter.com/NBA">@NBA</a>'s official <a
                        href="https://twitter.com/i/lists/17852612">NBA Players list</a>.</li>
                <ul>
                    <li>That list of NBA players itself is also a solid and reliable data source.</li>
                    <li>Additionally, Basketball Reference also provides a list of <a
                            href="https://www.basketball-reference.com/friv/twitter.html">NBA players' Twitter
                            handles</a>.</li>
                </ul>
                <li>Reddit posts from <a href="https://www.reddit.com/r/nba/">/r/nba</a> with <a
                        href="https://www.reddit.com/dev/api/">Reddit
                        API</a>.</li>
                <li><a href="https://data.fivethirtyeight.com/">FiveThirtyEight</a>’s NBA open data, including</li>
                <ul>
                    <li><a href="https://github.com/fivethirtyeight/data/tree/master/nba-raptor">RAPTOR</a></li>
                    <li><a href="https://github.com/fivethirtyeight/data/tree/master/nba-draymond">DRAYMOND</a></li>
                    <li><a href="https://github.com/fivethirtyeight/data/tree/master/nba-forecasts">Elo</a></li>
                    <li><a href="https://github.com/fivethirtyeight/data/tree/master/nba-elo">Historical Elo</a></li>
                    <li><a href="https://github.com/fivethirtyeight/nba-player-advanced-metrics">Advanced metrics</a>
                    </li>
                    <li><a href="https://github.com/fivethirtyeight/data/tree/master/nba-winprobs">NBA win
                            probabilities</a></li>
                </ul>
                <li><a href="https://pudding.cool/">The Pudding</a>’s NBA open data, including</li>
                <ul>
                    <li><a
                            href="https://github.com/polygraph-cool/last-two-minute-report/tree/master/output">last-two-minute-report</a>
                    </li>
                    <li><a href="https://github.com/the-pudding/data/tree/master/hype">hype</a></li>
                    <li><a href="https://pudding.cool/2019/03/sankey-nba-data/data-all.json">NBA player names with
                            hyphens</a></li>
                    <li><a href="https://github.com/the-pudding/data/tree/master/three-seconds">three-seconds</a></li>
                </ul>

                <li>Search term data from <a href="https://trends.google.com/trends/?geo=US">Google Trends</a>.</li>
                <li>Supporting data (partially included at this moment, will be updated when needed) from</li>
                <ul>
                    <li><a href="https://www.basketball-reference.com/">Basketball Reference</a>;</li>
                    <li><a href="https://github.com/alexnoob/BasketBall-GM-Rosters">BasketBall-GM-Rosters</a> and
                        potentially some
                        simulation data generated from
                        <a href="https://basketball-gm.com/">Basketball GM</a>.
                    </li>
                    <li><a href="https://www.nba.com/">NBA.com</a>;</li>
                    <li><a
                            href=" https://teamcolorcodes.com/nba-team-color-codes/ and https://en.wikipedia.org/wiki/Wikipedia:WikiProject_National_Basketball_Association/National_Basketball_Association_team_abbreviations">NBA
                            Team Abbreviations</a> from Wikipedia;</li>
                    <li><a href="https://teamcolorcodes.com/nba-team-color-codes/">NBA Team Color Codes</a> from Team
                        Color Codes;</li>
                    <li>21-22 season’s team schedules for computing the travel distance of each team.</li>
                    <li>More to come!</li>
                </ul>
            </ul>
        </section>

        <section id="methods">
            <h2>Gathering methods</h2>
        </section>

        <section id="pbp">
            <h2>Play-by-play data from PBP Stats</h2>
            <blockquote><a href="https://github.com/rexarski/box2box/tree/main/data/nba-pbp">Data</a></blockquote>

            <p><span>Thanks to Darryl Blackport for putting this up as one of the most complete and detailed
                    NBA in-game data sets online. Although it is a paid subscription on </span><a
                    href='https://www.patreon.com/pbpstats/posts'><span>Patreon</span></a><span>, he deserves every
                    penny of it. The dedication he puts into this project is unparalleled. Here is a snapshot of what
                    the data set looks like.</span></p>
            <figure>
                <img src="/img/02-pbp.png" alt="PBP Stats" class="article-img">
                <figcaption>Each shot was hand tracked, attached with a video link.</a>
                </figcaption>
            </figure>

            <p><span>After filtering a bunch of conditions on </span><a href='https://tracking.pbpstats.com/'><span>his
                        website</span></a><span>, the data can be directly exported in CSV format.</span></p>

            <figure>
                <img src="/img/02-pbp-csv.png" alt="PBP Stats Raw" class="article-img">
                <figcaption>PBP raw data.</a>
                </figcaption>
            </figure>
        </section>

        <section id="twitter">
            <h2>Twitter data</h2>
        </section>

        <section id="tweet">
            <h2>Text data from players' tweets</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/blob/main/data/nba-tweets/player-tweets.csv'><span>Data</span></a>
                </p>
                <p><a href='https://github.com/rexarski/box2box/blob/main/nba-player-tweet-scraper/tweet-scraper.py'><span>Python
                            script</span></a></p>
            </blockquote>
            <p><span>Twitter Dev API and Python’s tweepy library are used to scrape the tweets that appeared in
                </span><a href='https://twitter.com/NBA'><span>@NBA</span></a><span>’s </span><a
                    href='https://twitter.com/i/lists/17852612'><span>player list</span></a><span>.</span></p>
            <p><span>The raw data looks like this:</span></p>
            <figure>
                <img src="/img/02-player-tweets.png" alt="Player Tweets" class="article-img">
                <figcaption>Tweets raw data.</a>
                </figcaption>
            </figure>
            <p><span>Tweet id is used to mark the time range to scrape the tweets backward manually. However,
                    the Twitter API does not allow search by time. The id-trick is very inefficient. What’s worse is
                    that the limit of each request is only 500 tweets, which makes it even harder to
                    scrape backward from a list Twitter list.</span></p>
            <p><span>We might take a detour to get a shortlist of players first, then scrape their tweets individually.
                    The data at this moment is not enough for the following text mining.</span></p>
        </section>

        <section id="account">
            <h2>Player accounts data</h2>
            <blockquote>
                <p><a href='https://github.com/rexarski/box2box/blob/main/data/nba-tweets/player-accounts.csv'><span>Scraped
                            data</span></a><span>, </span><a
                        href='https://github.com/rexarski/box2box/blob/main/data/nba-tweets/player-accounts-br.csv'><span>data
                            from BR</span></a></p>
                <p><a href='https://github.com/rexarski/box2box/blob/main/nba-player-tweet-scraper/tweet-scraper.py'><span>Python
                            script</span></a></p>
            </blockquote>
            <p><span>The player accounts data is acquired in the same manner.</span></p>
            <figure>
                <img src="/img/02-player-account.png" alt="Account Data" class="article-img">
                <figcaption>Player account data.</a>
                </figcaption>
            </figure>
            <p><span>Additionally, </span><a
                    href='https://www.basketball-reference.com/friv/twitter.html'><span>Basketball Reference’s
                        list</span></a><span> is included as a compliment.</span></p>
            <figure>
                <img src="/img/02-player-account-br.png" alt="Account Data BR" class="article-img">
                <figcaption>Basketball Reference's player account data.</a>
                </figcaption>
            </figure>

            <p><span>It might be a good idea to include some metadata such as follower counts,
                    account created time, etc.</span></p>
        </section>

        <section id="reddit">
            <h2>Reddit data</h2>
            <blockquote>
                <p><a href='https://github.com/rexarski/box2box/tree/main/data/nba-reddit'><span>RDS data</span></a>, <a
                        href='https://github.com/rexarski/box2box/blob/main/data/nba-reddit/test-run.json'><span>JSON
                            data</span></a></p>
                <p><a href='https://github.com/rexarski/box2box/blob/main/reddit-nba-scraper/reddit-scraper.r'><span>R
                            script 1</span></a>, <a
                        href='https://github.com/rexarski/box2box/blob/main/reddit-nba-scraper/cron-job.r'><span>R
                            script 2 (GitHub Action)</span></a></p>
            </blockquote>
            <p><span>
                    For Reddit content scraping, its <a href='https://www.reddit.com/dev/api/'>API</a> is
                    more straightforward, but the documentation is <a
                        href='https://www.reddit.com/r/redditdev/comments/c93rdt/how_do_i_get_json_data_of_a_specific_post_without/'>poorly
                        structured</a>. In fact, only a certain amount of
                    data can be acquired. Specifically, there’s no way to retrieve all the comments from a thread, and
                    there is no way
                    to
                    work around this. If it is really necessary, it is strongly suggested to also consider using data
                    dumps like </span><a
                    href='https://files.pushshift.io/reddit/comments/'><span>PushShift</span></a><span>.</span></p>
            <p><span>In order to show that utilizing Reddit API with R is viable, some irrelevant
                    data is still scraped in this way. The script contains the metadata of user <b>rexarski</b>. </span>
            </p>

            <figure>
                <img src="/img/02-my-metadata.png" alt="Metadata of Reddit User rexarski" class="article-img">
                <figcaption>Metadata of Reddit user rexarski.</a>
                </figcaption>
            </figure>

            <p><span>Then reconsider what type of data should be prioritized in the data gathering process.
                    For this one, it should be the metadata of posts. It's not bad to take another shot at Reddit's
                    open
                    API, the one accessible even without a dev app registration. For instance,
                    <code>https://api.reddit.com/r/nba/top/?t=day</code>, should return a JSON of of 25 posts on
                    the front page of subreddit r/nba.</span></p>

            <figure>
                <img src="/img/02-reddit-api.png" alt="Direct API Access to Reddit" class="article-img">
                <figcaption>Direct API Access to Reddit.</a>
                </figcaption>
            </figure>

            <p><span>Naturally, the data is saved as a raw JSON file, which is accessible as <code>test-run.json</code>
                    in the repo.</span></p>

            <p><span>But this approach is not satisfying enough. It should be more painless. After some community
                    post browsing, an R package <a
                        href='https://github.com/ivan-rivera/RedditExtractoR'>RedditExtractoR</a> emerges. With its
                    power, it becomes much easier to save the top 10 posts in the r/nba subreddit in an R list. Since an
                    R list is a single R variable, it’s
                    perfect to store it in an .RDS file. One iteration of the script above will keep a daily copy of
                    such data. The general structure of that list is shown below:</span></p>

            <figure>
                <img src="/img/02-reddit-thread.png" alt="Reddit Thread Data Structure" class="article-img">
                <figcaption>Reddit thread data structure.</a>
                </figcaption>
            </figure>

            <p><span>Moreover, it is also a good practice to keep such time-sensitive data collection routine
                    as automated as possible. Therefore the a <a href='https://github.com/features/actions'>GitHub
                        Action</a> is deployed to fulfill the job.
                    Basically, a scheduled cron job inside the repository is set up to run a specified script in a
                    specified
                    environment. And thanks to <a href='https://github.com/marketplace/actions/git-auto-commit'>Git Auto
                        Commit</a> action developed by <a href='https://github.com/stefanzweifel'>Stefan Zweifel</a>,
                    the cron job is enabled to commit and push the scraped data to the repo automatically. To summarize,
                    the script runs
                    once a day (at say 21:02 UTC), gets the data, saves the data.</span></p>

            <figure>
                <img src="/img/02-github-actions.png" alt="GitHub Actions of the Reddit Scraper" class="article-img">
                <figcaption>GitHub Actions of the Reddit scraper.</a>
                </figcaption>
            </figure>

            <p><span>The Action setting file is located <a
                        href='https://github.com/rexarski/box2box/blob/main/.github/workflows/reddit-scraper.yml'>here</a>.</span>
            </p>

            <p><span>We can even checking the workflow status by looking at an SVG badge that GitHub
                    provides.</span></p>

            <svg>
                <image href='https://github.com/rexarski/box2box/actions/workflows/reddit-scraper.yml/badge.svg'>
                </image>
            </svg>

        </section>

        <section id="fivethirtyeight">
            <h2>FiveThirtyEight data</h2>
            <p><span>Starting from here, the current location of the data will be listed, and a brief introduction of
                    what they are about will follow. All data are copied from their original repositories
                    directly.</span></p>
        </section>

        <section id="raptor">
            <h2>RAPTOR</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-raptor'><span>Data</span></a>
                </p>
            </blockquote>
            <p><span>RAPTOR stands for Robust Algorithm (using) Player Tracking (and) On/Off Ratings. It is
                    FiveThirtyEight’s original NBA statistic.<sup><a href='#fn1' id='ref1'>1</a></sup>
                </span></p>
        </section>

        <section id="draymond">
            <h2>DRAYMOND</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-draymond'><span>Data</span></a>
                </p>
            </blockquote>
            <p><span>DRAYMOND stands for Defensive Rating Accounting for Yielding Minimal Openess by Nearest
                    Defender.<sup><a href='#fn2' id='ref2'>2</a></sup>
                    (538 is really good at coming up with an accronym.)</span></p>
        </section>

        <section id="more">
            <h2>More</h2>
            <blockquote>
                <ul>
                    <li>
                        <p><a
                                href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-forecasts-elo'><span>Elo</span></a>
                        </p>
                    </li>
                    <li>
                        <p><a
                                href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-historical-elo'><span>Historial
                                    Elo</span></a></p>
                    </li>
                    <li>
                        <p><a
                                href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-player-advanced-metrics'><span>Advanced
                                    metrics</span></a></p>
                    </li>
                    <li>
                        <p><a href='https://github.com/rexarski/box2box/tree/main/data/fivethirtyeight/nba-winprobs'><span>Win
                                    probabilities</span></a></p>
                    </li>
                </ul>
            </blockquote>
        </section>

        <section id="pudding">
            <h2>The Pudding data</h2>
            <p><span>It is copied from the original repositories as well.</span></p>
        </section>

        <section id="last-two-minute-report">
            <h2>last-two-minute-report</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/tree/main/data/the-pudding/last-two-minute-report'><span>Data</span></a>
                </p>
            </blockquote>
            <p><span>Data of NBA’s last two minute officiating reports.<sup><a href='#fn3' id='ref3'>3</a></sup>
                </span></p>
        </section>

        <section id="hype">
            <h2>hype</h2>
            <blockquote>
                <p><a href='https://github.com/rexarski/box2box/tree/main/data/the-pudding/hype'><span>Data and
                            script</span></a></p>
            </blockquote>
            <p><span>Data about the careers of 1,873 players.<sup><a href='#fn4' id='ref4'>4</a></sup>
                </span></p>
        </section>

        <section id="names">
            <h2>NBA player names with hyphens</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/blob/main/data/the-pudding/nba-player-names/data-all.json'><span>Data</span></a>
                </p>
            </blockquote>
            <p><span>The player names data <sup><a href='#fn5' id='ref5'>5</a></sup> is
                    provided in a JSON, downloaded by </span><code>wget</code><span>.</span></p>
            <figure>
                <img src="/img/02-wget-json.png" alt="wget JSON" class="article-img">
                <figcaption>Use bash command to retrieve data.</a>
                </figcaption>
            </figure>
        </section>

        <section id="three-seconds">
            <h2>three-seconds</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/tree/main/data/the-pudding/three-seconds'><span>Data</span></a>
                </p>
            </blockquote>
            <p><span>Data of every defensive three seconds call in the NBA between 2015-2018 (including
                    playoffs).<sup><a href='#fn6' id='ref6'>6</a></sup></span></p>
        </section>

        <section id="google-trends">
            <h2>Google Trends search term data</h2>
            <blockquote>
                <p><a
                        href='https://github.com/rexarski/box2box/tree/main/data/google-trends-taco-tuesday'><span>Data</span></a><span>.</span>
                </p>
            </blockquote>
            <p><span>The data is extracted from the page of Google Trends. After selecting some terms of interest, we
                    click the download button on the top right corner and extract CSV data. But note that, the numbers
                    in the data show relative interest on the Internet. They are not absolute values.</span></p>
            <figure>
                <img src="/img/02-google-trends.png" alt="Google Trends Data" class="article-img">
                <figcaption>Google Trends search term interest data.</a>
                </figcaption>
            </figure>
        </section>

        <section id="support">
            <h2>Supporting data</h2>
            <ul>
                <li><span>Basketball-GM’s </span><a
                        href='https://github.com/rexarski/box2box/tree/main/data/bgm-simulation'><span>2021-22 NBA
                            roster</span></a><span>.</span></li>
                <li><a href='https://github.com/rexarski/box2box/blob/main/data/nba-team-data/codes-and-colors.csv'><span>Team
                            information</span></a><span> including names, short codes, and colors.</span></li>
                <figure>
                    <img src="/img/02-team-data.png" alt="NBA Team Info" class="article-img">
                    <figcaption>Team short codes and colors.</a>
                    </figcaption>
                </figure>
            </ul>
        </section>

        <p><span>There will be lots of so-called “labor of
                love” in collecting and tidying those supporting data for sure in the future. Nevertheless, it is still
                a lot of fun.</span></p>

        <hr>

        <p><span><sup id='fn1'>1. <a
                        href='https://fivethirtyeight.com/features/introducing-raptor-our-new-metric-for-the-modern-nba/'>Introducing
                        RAPTOR, Our New Metric For The Modern NBA. (fivethirtyeight.com)</a><a href='#ref1'
                        title='Jump back to fn1 in the text.'>↩</a></sup></span></p>

        <p><span><sup id='fn2'>2. <a href='https://fivethirtyeight.com/features/a-better-way-to-evaluate-nba-defense/'>A
                        Better
                        Way To
                        Evaluate NBA Defense. (fivethirtyeight.com)</a><a href='#ref2' title='Jump back to footnote 2 in the
    text.'>↩</a></sup></span></p>

        <p><span><sup id='fn3'>3. <a href='https://pudding.cool/2017/02/two-minute-report/'>NBA Last Two Minute Report.
                        (pudding.cool)</a><a href='#ref3'
                        title='Jump back to footnote 3 in the text.'>↩</a></sup></span></p>

        <p><span><sup id='fn4'>4. <a href='https://pudding.cool/2019/03/hype/'>How many high school stars make it to the
                        NBA?
                        (pudding.cool)</a><a href='#ref4' title='Jump back to footnote 4 in the text.'>↩</a></sup>
            </span></p>

        <p><span><sup id='fn5'>5. <a href='https://pudding.cool/2019/03/nba-spelling/'>Spell Jam. (pudding.cool)</a><a
                        href='#ref5' title='Jump back to footnote 5 in the text.'>↩</a></sup></span></p>

        <p><span><sup id='fn6'>6. <a href='https://pudding.cool/2019/05/three-seconds/'>The NBA Has a Defensive Three
                        Seconds
                        Problem.
                        (pudding.cool)</a><a href='#ref6'
                        title='Jump back to footnote 6 in the text.'>↩</a></sup></span></p>

        <footer class="footer">
            <p>Copyright &copy; 2021 <a href="https://qrui.xyz">Ruì Qiū</a></p>
        </footer>
    </article>

    <script src="js/script.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };</script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</body>

</html>